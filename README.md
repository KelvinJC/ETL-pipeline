# Machine Learning ETL Pipeline

A data transformation job on data sourced from a MongoDB database. 
<br>
Input data was a deeply nested JSON format from a MongoDB source system.
<br>
During the transformation stage of the ETL, the data was normalised into structured relational format
<br>
for subsequent feature engineering and analysis to build a prediction model. 
<br>
The result dataset had over 56,000 features (i.e. columns).

## Languages and Libraries
* Python
* Jupyter Notebook
* Pandas
* Flatten_json
